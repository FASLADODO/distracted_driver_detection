{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop,SGD,Adadelta,Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import TensorBoard,History,EarlyStopping,CSVLogger\n",
    "from keras.applications.vgg19 import VGG19,preprocess_input\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './train'\n",
    "validation_path = './validation'\n",
    "test_path = './test'\n",
    "assert(os.path.exists(train_path))\n",
    "assert(os.path.exists(validation_path))\n",
    "assert(os.path.exists(test_path))\n",
    "\n",
    "\n",
    "nb_train_samples = 20000\n",
    "nb_val_samples = 2424\n",
    "image_size = (224,224)\n",
    "batch_size = 128\n",
    "class_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(img_path):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,test_path,csv='sample_submission.csv'):\n",
    "    columns = ['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    file_list = os.listdir(test_path)\n",
    "    for i,file in enumerate(file_list):\n",
    "        test_data = image_preprocess(test_path + '/' + file)\n",
    "        y_pred = model.predict(test_data,batch_size=1,verbose=0)\n",
    "        y_pred = np.clip(y_pred,0.001,0.999)\n",
    "        y_pred = y_pred[0].tolist()\n",
    "        df.loc[i] = [file] + y_pred\n",
    "        \n",
    "    df.to_csv(csv,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 10 classes.\n",
      "Found 2424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "                                         shear_range=0.15,\n",
    "                                         rotation_range=15,\n",
    "                                         height_shift_range=0.15,\n",
    "                                         width_shift_range=0.15,\n",
    "                                         channel_shift_range=10,\n",
    "                                         preprocessing_function=preprocess_input,\n",
    "                                         horizontal_flip=True)\n",
    "\n",
    "validation_datagen = image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                    train_path,\n",
    "                                    target_size=image_size,\n",
    "                                    batch_size=batch_size,\n",
    "                                    class_mode='categorical',\n",
    "                                    shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                                    validation_path,\n",
    "                                    target_size=image_size,\n",
    "                                    batch_size=batch_size,                                    \n",
    "                                    class_mode='categorical',\n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_base_model = VGG19(weights='imagenet', include_top=False,input_shape=(224,224,3))\n",
    "\n",
    "x = vgg19_base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "vgg19_model = Model(inputs=vgg19_base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_conv4 False\n",
      "11 block3_pool False\n",
      "12 block4_conv1 False\n",
      "13 block4_conv2 False\n",
      "14 block4_conv3 False\n",
      "15 block4_conv4 False\n",
      "16 block4_pool False\n",
      "17 block5_conv1 False\n",
      "18 block5_conv2 False\n",
      "19 block5_conv3 False\n",
      "20 block5_conv4 False\n",
      "21 block5_pool False\n",
      "22 flatten_1 True\n",
      "23 dense_1 True\n",
      "24 batch_normalization_1 True\n",
      "25 dropout_1 True\n",
      "26 dense_2 True\n",
      "27 batch_normalization_2 True\n",
      "28 dropout_2 True\n",
      "29 dense_3 True\n"
     ]
    }
   ],
   "source": [
    "for layer in vgg19_model.layers[:22]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i,layer in enumerate(vgg19_model.layers):\n",
    "    print(i,layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "156/156 [==============================] - 369s 2s/step - loss: 1.6290 - acc: 0.4868 - val_loss: 0.9036 - val_acc: 0.7188\n",
      "Epoch 2/15\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.5715 - acc: 0.8105 - val_loss: 0.7522 - val_acc: 0.8101\n",
      "Epoch 3/15\n",
      "156/156 [==============================] - 362s 2s/step - loss: 0.3832 - acc: 0.8753 - val_loss: 1.3856 - val_acc: 0.6777\n",
      "Epoch 4/15\n",
      "156/156 [==============================] - 358s 2s/step - loss: 0.3069 - acc: 0.9026 - val_loss: 0.9824 - val_acc: 0.7622\n",
      "Epoch 5/15\n",
      "156/156 [==============================] - 357s 2s/step - loss: 0.2577 - acc: 0.9173 - val_loss: 0.9428 - val_acc: 0.7565\n",
      "Epoch 6/15\n",
      "156/156 [==============================] - 358s 2s/step - loss: 0.2250 - acc: 0.9272 - val_loss: 1.3254 - val_acc: 0.7152\n",
      "Epoch 7/15\n",
      "156/156 [==============================] - 357s 2s/step - loss: 0.2103 - acc: 0.9325 - val_loss: 1.3454 - val_acc: 0.7108\n"
     ]
    }
   ],
   "source": [
    "vgg19_model.compile(loss='categorical_crossentropy',\n",
    "                    #optimizer=optimizers.SGD(lr=1e-3, momentum=0.9) #,decay=1e-6,nesterov=True),\n",
    "                    optimizer=optimizers.Adam(lr=1e-3),\n",
    "#                     optimizer=Adadelta(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# fine-tune the model\n",
    "vgg19_model.fit_generator(\n",
    "                        train_generator,\n",
    "                        steps_per_epoch=nb_train_samples // batch_size,\n",
    "                        epochs=15,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=nb_val_samples // batch_size,\n",
    "                        callbacks=[EarlyStopping(patience=5)])\n",
    "\n",
    "vgg19_model.save('vgg19_model_fc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg19_model.compile(loss='categorical_crossentropy',\n",
    "#                     optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), #,decay=1e-6,nesterov=True),\n",
    "#                     #optimizer=optimizers.Adam(lr=1e-3),\n",
    "# #                     optimizer=Adadelta(),\n",
    "#                     metrics=['accuracy'])\n",
    "\n",
    "# # fine-tune the model\n",
    "# vgg19_model.fit_generator(\n",
    "#                         train_generator,\n",
    "#                         steps_per_epoch=nb_train_samples // batch_size,\n",
    "#                         epochs=10,\n",
    "#                         validation_data=validation_generator,\n",
    "#                         validation_steps=nb_val_samples // batch_size,\n",
    "#                         callbacks=[EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg19_model.save('vgg19_model_fc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "156/156 [==============================] - 361s 2s/step - loss: 0.1704 - acc: 0.9455 - val_loss: 0.8922 - val_acc: 0.7843\n",
      "Epoch 2/20\n",
      "156/156 [==============================] - 358s 2s/step - loss: 0.0709 - acc: 0.9786 - val_loss: 0.8188 - val_acc: 0.8436\n",
      "Epoch 3/20\n",
      "156/156 [==============================] - 356s 2s/step - loss: 0.0520 - acc: 0.9850 - val_loss: 0.8832 - val_acc: 0.7827\n",
      "Epoch 4/20\n",
      "156/156 [==============================] - 352s 2s/step - loss: 0.0300 - acc: 0.9914 - val_loss: 0.8014 - val_acc: 0.8367\n",
      "Epoch 5/20\n",
      "156/156 [==============================] - 357s 2s/step - loss: 0.0442 - acc: 0.9875 - val_loss: 1.2659 - val_acc: 0.8445\n",
      "Epoch 6/20\n",
      "156/156 [==============================] - 364s 2s/step - loss: 0.0302 - acc: 0.9909 - val_loss: 0.8130 - val_acc: 0.8271\n",
      "Epoch 7/20\n",
      "156/156 [==============================] - 360s 2s/step - loss: 0.0210 - acc: 0.9937 - val_loss: 0.5826 - val_acc: 0.8724\n",
      "Epoch 8/20\n",
      "156/156 [==============================] - 361s 2s/step - loss: 0.0201 - acc: 0.9935 - val_loss: 1.3163 - val_acc: 0.7574\n",
      "Epoch 9/20\n",
      "156/156 [==============================] - 363s 2s/step - loss: 0.0165 - acc: 0.9950 - val_loss: 0.5988 - val_acc: 0.8715\n",
      "Epoch 10/20\n",
      "156/156 [==============================] - 359s 2s/step - loss: 0.0114 - acc: 0.9967 - val_loss: 0.9233 - val_acc: 0.7905\n",
      "Epoch 11/20\n",
      "156/156 [==============================] - 357s 2s/step - loss: 0.0086 - acc: 0.9979 - val_loss: 0.6878 - val_acc: 0.8371\n",
      "Epoch 12/20\n",
      "156/156 [==============================] - 359s 2s/step - loss: 0.0168 - acc: 0.9956 - val_loss: 1.1213 - val_acc: 0.7783\n"
     ]
    }
   ],
   "source": [
    "vgg19_model = load_model('vgg19_model_fc.h5')\n",
    "\n",
    "for layer in vgg19_model.layers[:17]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in vgg19_model.layers[17:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "vgg19_model.compile(loss='categorical_crossentropy',\n",
    "#                     optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), #decay=1e-6,nesterov=True),\n",
    "                    optimizer=optimizers.Adam(lr=1e-4),\n",
    "                    metrics=['accuracy'])  \n",
    "\n",
    "vgg19_model.fit_generator(\n",
    "                        train_generator,\n",
    "                        steps_per_epoch=nb_train_samples // batch_size,\n",
    "                        epochs=20,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=nb_val_samples // batch_size,\n",
    "                        callbacks=[TensorBoard(log_dir='./logs/vgg19_fine_tune'),\n",
    "                                   CSVLogger('vgg19_fine_tune'), #])\n",
    "                                   EarlyStopping(patience=5)])\n",
    "\n",
    "vgg19_model.save('vgg19_model_17.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "156/156 [==============================] - 377s 2s/step - loss: 0.0690 - acc: 0.9780 - val_loss: 0.5876 - val_acc: 0.8863\n",
      "Epoch 2/20\n",
      "156/156 [==============================] - 371s 2s/step - loss: 0.0348 - acc: 0.9896 - val_loss: 0.4925 - val_acc: 0.8576\n",
      "Epoch 3/20\n",
      "156/156 [==============================] - 372s 2s/step - loss: 0.0428 - acc: 0.9872 - val_loss: 0.9329 - val_acc: 0.8545\n",
      "Epoch 4/20\n",
      "156/156 [==============================] - 372s 2s/step - loss: 0.0234 - acc: 0.9927 - val_loss: 1.1357 - val_acc: 0.8380\n",
      "Epoch 5/20\n",
      "156/156 [==============================] - 372s 2s/step - loss: 0.0268 - acc: 0.9917 - val_loss: 0.7727 - val_acc: 0.8432\n",
      "Epoch 6/20\n",
      "156/156 [==============================] - 371s 2s/step - loss: 0.0231 - acc: 0.9935 - val_loss: 0.4792 - val_acc: 0.8855\n",
      "Epoch 7/20\n",
      "156/156 [==============================] - 373s 2s/step - loss: 0.0199 - acc: 0.9949 - val_loss: 0.9648 - val_acc: 0.8262\n",
      "Epoch 8/20\n",
      "156/156 [==============================] - 371s 2s/step - loss: 0.0220 - acc: 0.9936 - val_loss: 0.9613 - val_acc: 0.8092\n",
      "Epoch 9/20\n",
      "156/156 [==============================] - 371s 2s/step - loss: 0.0174 - acc: 0.9951 - val_loss: 1.3520 - val_acc: 0.7861\n",
      "Epoch 10/20\n",
      "156/156 [==============================] - 371s 2s/step - loss: 0.0114 - acc: 0.9965 - val_loss: 0.3965 - val_acc: 0.9220\n",
      "Epoch 11/20\n",
      "156/156 [==============================] - 373s 2s/step - loss: 0.0095 - acc: 0.9974 - val_loss: 1.2015 - val_acc: 0.7809\n",
      "Epoch 12/20\n",
      "156/156 [==============================] - 370s 2s/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.4126 - val_acc: 0.9268\n",
      "Epoch 13/20\n",
      "156/156 [==============================] - 372s 2s/step - loss: 0.0134 - acc: 0.9960 - val_loss: 0.8389 - val_acc: 0.8767\n",
      "Epoch 14/20\n",
      "156/156 [==============================] - 371s 2s/step - loss: 0.0164 - acc: 0.9952 - val_loss: 1.1770 - val_acc: 0.8314\n",
      "Epoch 15/20\n",
      "156/156 [==============================] - 373s 2s/step - loss: 0.0181 - acc: 0.9945 - val_loss: 0.9673 - val_acc: 0.8127\n"
     ]
    }
   ],
   "source": [
    "vgg19_model = load_model('vgg19_model_17.h5')\n",
    "\n",
    "for layer in vgg19_model.layers[:12]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in vgg19_model.layers[12:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "vgg19_model.compile(loss='categorical_crossentropy',\n",
    "#                     optimizer=optimizers.SGD(lr=1e-4, momentum=0.9,decay=1e-6,nesterov=True),\n",
    "                    optimizer=optimizers.Adam(lr=1e-4),\n",
    "                    metrics=['accuracy'])  \n",
    "\n",
    "vgg19_model.fit_generator(\n",
    "                        train_generator,\n",
    "                        steps_per_epoch=nb_train_samples // batch_size,\n",
    "                        epochs=20,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=nb_val_samples // batch_size,\n",
    "                        callbacks=[TensorBoard(log_dir='./logs/vgg19_fine_tune'),\n",
    "                                   CSVLogger('vgg19_fine_tune'), #])\n",
    "                                   EarlyStopping(patience=5)])\n",
    "\n",
    "vgg19_model.save('vgg19_model_12.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg19_model.compile(loss='categorical_crossentropy',\n",
    "# #                     optimizer=optimizers.SGD(lr=1e-4, momentum=0.9,decay=1e-6,nesterov=True),\n",
    "#                     optimizer=optimizers.Adam(lr=1e-4),\n",
    "#                     metrics=['accuracy'])  \n",
    "\n",
    "# vgg19_model.fit_generator(\n",
    "#                         train_generator,\n",
    "#                         steps_per_epoch=nb_train_samples // batch_size,\n",
    "#                         epochs=50,\n",
    "#                         validation_data=validation_generator,\n",
    "#                         validation_steps=nb_val_samples // batch_size,\n",
    "#                         callbacks=[TensorBoard(log_dir='./logs/vgg19_fine_tune'),\n",
    "#                                    CSVLogger('vgg19_fine_tune'), #])\n",
    "#                                    EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg19_model.save('vgg19_model_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "156/156 [==============================] - 372s 2s/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.4806 - val_acc: 0.9080\n",
      "Epoch 2/50\n",
      "156/156 [==============================] - 373s 2s/step - loss: 0.0099 - acc: 0.9966 - val_loss: 0.5491 - val_acc: 0.8937\n",
      "Epoch 3/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0070 - acc: 0.9983 - val_loss: 0.6186 - val_acc: 0.8759\n",
      "Epoch 4/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.6585 - val_acc: 0.8685\n",
      "Epoch 5/50\n",
      "156/156 [==============================] - 366s 2s/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.6364 - val_acc: 0.8733\n",
      "Epoch 6/50\n",
      "156/156 [==============================] - 367s 2s/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.5697 - val_acc: 0.8868\n",
      "Epoch 7/50\n",
      "156/156 [==============================] - 372s 2s/step - loss: 0.0079 - acc: 0.9976 - val_loss: 0.6478 - val_acc: 0.8728\n",
      "Epoch 8/50\n",
      "156/156 [==============================] - 371s 2s/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.6551 - val_acc: 0.8720\n",
      "Epoch 9/50\n",
      "156/156 [==============================] - 371s 2s/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.6585 - val_acc: 0.8711\n",
      "Epoch 10/50\n",
      "156/156 [==============================] - 372s 2s/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.6508 - val_acc: 0.8711\n",
      "Epoch 11/50\n",
      "156/156 [==============================] - 372s 2s/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.6481 - val_acc: 0.8715\n",
      "Epoch 12/50\n",
      "156/156 [==============================] - 372s 2s/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.6459 - val_acc: 0.8720\n",
      "Epoch 13/50\n",
      "156/156 [==============================] - 370s 2s/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.6419 - val_acc: 0.8724\n",
      "Epoch 14/50\n",
      "156/156 [==============================] - 368s 2s/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.6361 - val_acc: 0.8733\n",
      "Epoch 15/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.6315 - val_acc: 0.8741\n",
      "Epoch 16/50\n",
      "156/156 [==============================] - 366s 2s/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.6051 - val_acc: 0.8798\n",
      "Epoch 17/50\n",
      "156/156 [==============================] - 370s 2s/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.6024 - val_acc: 0.8794\n",
      "Epoch 18/50\n",
      "156/156 [==============================] - 372s 2s/step - loss: 0.0065 - acc: 0.9983 - val_loss: 0.6298 - val_acc: 0.8750\n",
      "Epoch 19/50\n",
      "156/156 [==============================] - 368s 2s/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.6289 - val_acc: 0.8737\n",
      "Epoch 20/50\n",
      "156/156 [==============================] - 369s 2s/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.4310 - val_acc: 0.9145\n",
      "Epoch 21/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0060 - acc: 0.9986 - val_loss: 0.4899 - val_acc: 0.8998\n",
      "Epoch 22/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0069 - acc: 0.9979 - val_loss: 0.5648 - val_acc: 0.8820\n",
      "Epoch 23/50\n",
      "156/156 [==============================] - 367s 2s/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.6071 - val_acc: 0.8750\n",
      "Epoch 24/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0057 - acc: 0.9982 - val_loss: 0.5967 - val_acc: 0.8798\n",
      "Epoch 25/50\n",
      "156/156 [==============================] - 363s 2s/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.5470 - val_acc: 0.8916\n",
      "Epoch 26/50\n",
      "156/156 [==============================] - 367s 2s/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.6107 - val_acc: 0.8772\n",
      "Epoch 27/50\n",
      "156/156 [==============================] - 367s 2s/step - loss: 0.0051 - acc: 0.9988 - val_loss: 0.6181 - val_acc: 0.8759\n",
      "Epoch 28/50\n",
      "156/156 [==============================] - 368s 2s/step - loss: 0.0052 - acc: 0.9986 - val_loss: 0.6170 - val_acc: 0.8750\n",
      "Epoch 29/50\n",
      "156/156 [==============================] - 370s 2s/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.6179 - val_acc: 0.8746\n",
      "Epoch 30/50\n",
      "156/156 [==============================] - 367s 2s/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.6136 - val_acc: 0.8754\n",
      "Epoch 31/50\n",
      "156/156 [==============================] - 366s 2s/step - loss: 0.0059 - acc: 0.9979 - val_loss: 0.6122 - val_acc: 0.8759\n",
      "Epoch 32/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.6098 - val_acc: 0.8759\n",
      "Epoch 33/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.6064 - val_acc: 0.8763\n",
      "Epoch 34/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.6033 - val_acc: 0.8772\n",
      "Epoch 35/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0050 - acc: 0.9989 - val_loss: 0.5806 - val_acc: 0.8820\n",
      "Epoch 36/50\n",
      "156/156 [==============================] - 368s 2s/step - loss: 0.0048 - acc: 0.9990 - val_loss: 0.5725 - val_acc: 0.8820\n",
      "Epoch 37/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.6013 - val_acc: 0.8772\n",
      "Epoch 38/50\n",
      "156/156 [==============================] - 367s 2s/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.5996 - val_acc: 0.8772\n",
      "Epoch 39/50\n",
      "156/156 [==============================] - 366s 2s/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.4062 - val_acc: 0.9171\n",
      "Epoch 40/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.4660 - val_acc: 0.9020\n",
      "Epoch 41/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.5418 - val_acc: 0.8841\n",
      "Epoch 42/50\n",
      "156/156 [==============================] - 366s 2s/step - loss: 0.0060 - acc: 0.9980 - val_loss: 0.5876 - val_acc: 0.8763\n",
      "Epoch 43/50\n",
      "156/156 [==============================] - 368s 2s/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.5770 - val_acc: 0.8802\n",
      "Epoch 44/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.5320 - val_acc: 0.8911\n",
      "Epoch 45/50\n",
      "156/156 [==============================] - 364s 2s/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.5889 - val_acc: 0.8780\n",
      "Epoch 46/50\n",
      "156/156 [==============================] - 366s 2s/step - loss: 0.0045 - acc: 0.9991 - val_loss: 0.5965 - val_acc: 0.8759\n",
      "Epoch 47/50\n",
      "156/156 [==============================] - 366s 2s/step - loss: 0.0049 - acc: 0.9989 - val_loss: 0.5979 - val_acc: 0.8754\n",
      "Epoch 48/50\n",
      "156/156 [==============================] - 367s 2s/step - loss: 0.0042 - acc: 0.9990 - val_loss: 0.5968 - val_acc: 0.8754\n",
      "Epoch 49/50\n",
      "156/156 [==============================] - 367s 2s/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.5917 - val_acc: 0.8763\n",
      "Epoch 50/50\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.5932 - val_acc: 0.8772\n"
     ]
    }
   ],
   "source": [
    "vgg19_model = load_model('vgg19_model_12.h5')\n",
    "\n",
    "for layer in vgg19_model.layers[:12]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in vgg19_model.layers[12:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "vgg19_model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.SGD(lr=1e-5, momentum=0.9),#decay=1e-6,nesterov=True),\n",
    "#                     optimizer=optimizers.Adam(),\n",
    "                    metrics=['accuracy'])  \n",
    "\n",
    "vgg19_model.fit_generator(\n",
    "                        train_generator,\n",
    "                        steps_per_epoch=nb_train_samples // batch_size,\n",
    "                        epochs=50,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=nb_val_samples // batch_size,\n",
    "                        callbacks=[TensorBoard(log_dir='./logs/vgg19_fine_tune'),\n",
    "                                   CSVLogger('vgg19_fine_tune')])\n",
    "#                                    EarlyStopping(patience=3)])\n",
    "\n",
    "vgg19_model.save('vgg19_final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model.save('vgg19_final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model = load_model('vgg19_final_model.h5')\n",
    "\n",
    "test_model(vgg19_model,test_path,csv='vgg19_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
