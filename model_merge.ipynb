{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop,SGD,Adadelta,Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import TensorBoard,History,EarlyStopping,CSVLogger\n",
    "from keras.applications.vgg19 import VGG19,preprocess_input\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './train'\n",
    "validation_path = './validation'\n",
    "test_path = './test'\n",
    "assert(os.path.exists(train_path))\n",
    "assert(os.path.exists(validation_path))\n",
    "assert(os.path.exists(test_path))\n",
    "\n",
    "\n",
    "nb_train_samples = 20000\n",
    "nb_val_samples = 2424\n",
    "image_size = (224,224)\n",
    "batch_size = 128\n",
    "class_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(img_path):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,test_path,csv='sample_submission.csv'):\n",
    "    columns = ['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    file_list = os.listdir(test_path)\n",
    "    for i,file in enumerate(file_list):\n",
    "        test_data = image_preprocess(test_path + '/' + file)\n",
    "        y_pred = model.predict(test_data,batch_size=1,verbose=0)\n",
    "        y_pred = np.clip(y_pred,0.001,0.999)\n",
    "        y_pred = y_pred[0].tolist()\n",
    "        df.loc[i] = [file] + y_pred\n",
    "        \n",
    "    df.to_csv(csv,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensenble_models(models,model_input):\n",
    "    outputs = [model(model_input) for model in models]\n",
    "    \n",
    "    avrg = average(outputs)\n",
    "    \n",
    "    model = Model(inputs=model_input, outputs=avrg, name='ensemble_model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16_model (Model)             (None, 10)           21207882    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vgg19_model (Model)             (None, 10)           26517578    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 10)           0           vgg16_model[1][0]                \n",
      "                                                                 vgg19_model[1][0]                \n",
      "==================================================================================================\n",
      "Total params: 47,725,460\n",
      "Trainable params: 43,662,356\n",
      "Non-trainable params: 4,063,104\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = load_model('vgg16_final_model.h5')\n",
    "vgg16_model.name = 'vgg16_model'\n",
    "\n",
    "vgg19_model = load_model('vgg19_final_model.h5')\n",
    "vgg19_model.name = 'vgg19_model'\n",
    "\n",
    "models = [vgg16_model,vgg19_model]\n",
    "\n",
    "model_input = Input(shape=models[0].input_shape[1:])\n",
    "\n",
    "ensenble_model = ensenble_models(models,model_input)\n",
    "\n",
    "ensenble_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(ensenble_model,test_path=test_path,csv='vgg16_and_vgg19_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "('The name \"conv2d_27_input\" is used 2 times in the model. All layer names should be unique. Layer names: ', ['conv2d_27_input', 'conv2d_27_input', 'conv2d_27', 'conv2d_27', 'batch_normalization_15', 'batch_normalization_15', 'max_pooling2d_24', 'max_pooling2d_24', 'conv2d_28', 'conv2d_28', 'batch_normalization_16', 'batch_normalization_16', 'max_pooling2d_25', 'max_pooling2d_25', 'conv2d_29', 'conv2d_29', 'batch_normalization_17', 'batch_normalization_17', 'max_pooling2d_26', 'max_pooling2d_26', 'flatten_9', 'flatten_9', 'dense_17', 'dense_17', 'batch_normalization_18', 'batch_normalization_18', 'dropout_11', 'dropout_11', 'dense_18', 'dense_18', 'average_8'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-59f5a9c7da84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m   1825\u001b[0m                                    \u001b[0;34m' times in the model. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m                                    \u001b[0;34m'All layer names should be unique. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1827\u001b[0;31m                                    'Layer names: ', all_names)\n\u001b[0m\u001b[1;32m   1828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1829\u001b[0m         \u001b[0;31m# Layer parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ('The name \"conv2d_27_input\" is used 2 times in the model. All layer names should be unique. Layer names: ', ['conv2d_27_input', 'conv2d_27_input', 'conv2d_27', 'conv2d_27', 'batch_normalization_15', 'batch_normalization_15', 'max_pooling2d_24', 'max_pooling2d_24', 'conv2d_28', 'conv2d_28', 'batch_normalization_16', 'batch_normalization_16', 'max_pooling2d_25', 'max_pooling2d_25', 'conv2d_29', 'conv2d_29', 'batch_normalization_17', 'batch_normalization_17', 'max_pooling2d_26', 'max_pooling2d_26', 'flatten_9', 'flatten_9', 'dense_17', 'dense_17', 'batch_normalization_18', 'batch_normalization_18', 'dropout_11', 'dropout_11', 'dense_18', 'dense_18', 'average_8'])"
     ]
    }
   ],
   "source": [
    "model1 = load_model('simple_cnn_final_model.h5')\n",
    "model2= load_model('simple_cnn_final_model.h5')\n",
    "\n",
    "input1 = model1.input\n",
    "input2 = model2.input\n",
    "\n",
    "# layer1 = model1.get_layer(index=-2)\n",
    "# layer2 = model2.get_layer(index=-2)\n",
    "\n",
    "# avrg_layer = average([layer1,layer2])\n",
    "# out = Dense(10, activation='softmax')(avrg_layer)\n",
    "output1 = model1.output\n",
    "output2 = model2.output\n",
    "\n",
    "out = Average()([output1,output2])\n",
    "\n",
    "model = Model(inputs=[input1,input2],outputs=out)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
